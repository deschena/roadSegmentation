{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5220,
     "status": "ok",
     "timestamp": 1608042891382,
     "user": {
      "displayName": "Germain Fragnière",
      "photoUrl": "",
      "userId": "11075373030229809982"
     },
     "user_tz": -60
    },
    "id": "jEr0AdMJzhw6",
    "outputId": "4fc3ab90-e0a7-440b-ebb8-7b0c7d7a2a32"
   },
   "outputs": [],
   "source": [
    "!ssh-keygen -t rsa -b 4096\r\n",
    "!ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\r\n",
    "!cat /root/.ssh/id_rsa.pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103711,
     "status": "ok",
     "timestamp": 1608043011039,
     "user": {
      "displayName": "Germain Fragnière",
      "photoUrl": "",
      "userId": "11075373030229809982"
     },
     "user_tz": -60
    },
    "id": "O-_ODVM9z0TI",
    "outputId": "46a0c49c-2fb9-485e-ee35-a47fd941af9a"
   },
   "outputs": [],
   "source": [
    "!ssh -T git@github.com\r\n",
    "!git config --global user.email \"justin.deschenauxy@epfl.com\"\r\n",
    "!git config --global user.name \"Justin-Collab\"\r\n",
    "!git clone git@github.com:deschena/colab_unet_train.git\r\n",
    "!mv colab_unet_train/* .\r\n",
    "from google.colab import drive\r\n",
    "drive.mount('/content/gdrive')\r\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1608043406728,
     "user": {
      "displayName": "Germain Fragnière",
      "photoUrl": "",
      "userId": "11075373030229809982"
     },
     "user_tz": -60
    },
    "id": "wkXuMSgTzd7A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os, sys, io, random\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "\n",
    "from datasets.AugmDataset import AugmDataset\n",
    "from datasets.ToLabelDataset import ToLabelDataset\n",
    "from models.Unet import Unet\n",
    "from models.DenseUnet import DenseUnet\n",
    "from utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpWNkB_czd7H"
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1608043406732,
     "user": {
      "displayName": "Germain Fragnière",
      "photoUrl": "",
      "userId": "11075373030229809982"
     },
     "user_tz": -60
    },
    "id": "znv4FZwlzd7J"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "root_path = \"datasets/augmented_dataset/\"\n",
    "train_name_simple = \"train_clean/\"\n",
    "valid_name_simple = \"valid_clean/\"\n",
    "\n",
    "train_name_massa = \"train_base_n_massach\"\n",
    "valid_name_massa = \"valid_base_n_massach\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 998,
     "status": "ok",
     "timestamp": 1608043406734,
     "user": {
      "displayName": "Germain Fragnière",
      "photoUrl": "",
      "userId": "11075373030229809982"
     },
     "user_tz": -60
    },
    "id": "cWjonsh2zd7K"
   },
   "outputs": [],
   "source": [
    "def train_net(net, train_name, valid_name, seed=999, max_epoch=50, net_name=\"DEFAULT\", patience=5, verbose=True, batch_size=4):\n",
    "    torch.random.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    root_path = \"datasets/augmented_dataset/\"\n",
    "    \n",
    "    # Since we had the best results with only the binary cross entropy, we combine the final sigmoïd \n",
    "    # activation with the loss, since that way we have a numerically more stable result, as the \n",
    "    # log-sum-exp trick is used.\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train_set = AugmDataset(root_dir=root_path, name=train_name)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=batch_size)    \n",
    "\n",
    "    validation_set = AugmDataset(root_dir=root_path,name=valid_name)\n",
    "    validation_loader = DataLoader(validation_set, batch_size=2*batch_size, shuffle=False, num_workers=2*batch_size)\n",
    "    \n",
    "    # Send to GPU, prepare optimizer and learning rate scheduler\n",
    "    net.to(device)\n",
    "    optimizer = optim.Adam(net.parameters())\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=patience, verbose=verbose)\n",
    "    \n",
    "    validation_loss = []\n",
    "    training_loss = []\n",
    "    loss = -1\n",
    "    best_current_loss = -1\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "        net.train()\n",
    "        for batch_train, batch_gt in train_loader:\n",
    "            \n",
    "            # Send data to gpu\n",
    "            batch_train = batch_train.to(device)\n",
    "            batch_gt = batch_gt.to(device)\n",
    "            \n",
    "            # Clear accumulated gradients & compute prediction\n",
    "            optimizer.zero_grad()\n",
    "            output = net(batch_train)\n",
    "            # Compute loss, gradient & update parameters\n",
    "            loss = criterion(output, batch_gt)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # After each epoch, compute & save loss on training and validation sets\n",
    "        v_perf = validation_perf(net, validation_loader)\n",
    "        validation_loss.append(v_perf)\n",
    "        training_loss.append(loss)\n",
    "        # Check if scheduler must decrease learning rate\n",
    "        scheduler.step(v_perf)\n",
    "        if v_perf > best_current_loss:\n",
    "            # Save best net\n",
    "            torch.save(net.state_dict(), f\"/content/gdrive/My Drive/ML files/model_selection/{net_name}.pth\")\n",
    "            v_perf = best_current_loss\n",
    "        if verbose and epoch % 10 == 0:\n",
    "            print(f\"{epoch} epochs elapsed\")\n",
    "            \n",
    "    return training_loss, validation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB2YS_cwzd7L"
   },
   "source": [
    "## Train the models\n",
    "**Models considered**:\n",
    "1. Standard Unet\n",
    "2. Dense Attention Unet (pixel attention)\n",
    "\n",
    "These models are the ones that yielded the best results in the previous phase. Therefore, we train them both with 80% of labelled data as training samples. We also train them once by including the massachussets dataset. Since we want the highest score possible, we do not keep a test set, we will test the result directly on aicrowd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note**: The last layer of the sigmoid is deactivated during training because it is included in the loss, indeed, it yields a more stable function by leveraging the \"log-sum-exp\" trick. When the model is in eval mode, or activation_output is True, the last layer is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4002201,
     "status": "ok",
     "timestamp": 1608047410341,
     "user": {
      "displayName": "Germain Fragnière",
      "photoUrl": "",
      "userId": "11075373030229809982"
     },
     "user_tz": -60
    },
    "id": "KqGuF7M5zd7L",
    "outputId": "ce7c46f5-160b-496c-a032-8e2a6d63b6f9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "net1 = Unet(activation_output=False)\n",
    "net1_tr, net1_val = train_net(net1, train_name, valid_name, net_name=\"unet_simple\", seed=4432)\n",
    "np.save(f\"/content/gdrive/My Drive/ML files/model_selection/unet_tr_loss\", net1_tr)\n",
    "np.save(f\"/content/gdrive/My Drive/ML files/model_selection/unet_val_loss\", net1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4002201,
     "status": "ok",
     "timestamp": 1608047410341,
     "user": {
      "displayName": "Germain Fragnière",
      "photoUrl": "",
      "userId": "11075373030229809982"
     },
     "user_tz": -60
    },
    "id": "KqGuF7M5zd7L",
    "outputId": "ce7c46f5-160b-496c-a032-8e2a6d63b6f9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "net2 = Unet(activation_output=False)\n",
    "net2_tr, net2_val = train_net(net2, train_name, valid_name, net_name=\"unet_massach\", seed=98893)\n",
    "np.save(f\"/content/gdrive/My Drive/ML files/model_selection/unet_massach_tr_loss\", net2_tr)\n",
    "np.save(f\"/content/gdrive/My Drive/ML files/model_selection/unet_massach_val_loss\", net2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_Ua2FDqzd7P",
    "outputId": "2465df3d-3277-4a9e-c5c9-d7797edfb5c7"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "net3 = DenseUnet(down_config=(4, 8, 16, 32), bottom=64, up_channels=(256, 128, 64, 32), activation_output=False, attention=\"grid\")\n",
    "net3_tr, net3_val = train_net(net3, train_name, valid_name, net_name=\"dense_unet_simple\", seed=123123)\n",
    "np.save(f\"/content/gdrive/My Drive/ML files/model_selection/densenet_tr_loss\", net3_tr)\n",
    "np.save(f\"/content/gdrive/My Drive/ML files/model_selection/densetnet_val_loss\", net3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_Ua2FDqzd7P",
    "outputId": "2465df3d-3277-4a9e-c5c9-d7797edfb5c7"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "net4 = DenseUnet(down_config=(4, 8, 16, 32), bottom=64, up_channels=(256, 128, 64, 32), activation_output=False, attention=\"grid\")\n",
    "net4_tr, net4_val = train_net(net4, train_name, valid_name, net_name=\"dense_unet_massach\", seed=34422)\n",
    "np.save(f\"/content/gdrive/My Drive/ML files/model_selection/densenet_massach_tr_loss\", net4_tr)\n",
    "np.save(f\"/content/gdrive/My Drive/ML files/model_selection/densenet_massach_val_loss\", net4_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the performance of each loss\n",
    "After training those 4 U-nets, we created submissions for each of them in order to assess their perf on aicrowd. No test set this time, as we want the score to be as high as possible for the leaderboard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_larger_image(img, model, excess = 0, model_input = 256):\n",
    "    \"\"\"Split the original image in a set of 256*256 images that cover the first image\"\"\"\n",
    "    # img shape: (batch size = 1, channels, height, width)\n",
    "    width = img.shape[2]\n",
    "    height = img.shape[3]\n",
    "    N_V = height // model_input + 1 + excess # Number of images on vertical axis\n",
    "    N_H = width // model_input + 1 + excess # Number of images on horizontal axis\n",
    "    r_h = np.round(np.linspace(0, width  - model_input,  N_H)) # starting points on h axis\n",
    "    r_v = np.round(np.linspace(0, height - model_input, N_V)).astype(\"int\") # starting points on v axis\n",
    "    \n",
    "    result = np.zeros((width, height))\n",
    "    mask = np.zeros((width, height))\n",
    "    # NOTE : for some reason, using v & h as indices yields an error. So we cast them in int manually\n",
    "    for v in r_v:\n",
    "        v = int(v)\n",
    "        for h in r_h:\n",
    "            h = int(h)\n",
    "            sub_image = img[:, :, v: v + model_input, h: h + model_input]\n",
    "            if sub_image.shape[2] != model_input or sub_image.shape[3] != model_input:\n",
    "                raise Exception('Wrong input size')\n",
    "            with torch.no_grad():\n",
    "                # Predict\n",
    "                sub_pred = model(sub_image).squeeze()\n",
    "                sub_pred = sub_pred.to(\"cpu\").numpy()\n",
    "                # Add to total\n",
    "                result[v: v + model_input, h: h + model_input] += sub_pred\n",
    "                mask[v: v + model_input, h: h + model_input] += np.ones((model_input, model_input))\n",
    "    result /= mask\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_to_submission import *\n",
    "def create_submission(submission_filename, temp_dirname, model):\n",
    "    \n",
    "    test_dataset = ToLabelDataset()\n",
    "    if not os.path.exists(temp_dirname):\n",
    "        os.mkdir(temp_dirname)\n",
    "\n",
    "    image_filenames = []\n",
    "    for i in range(50):\n",
    "        img = test_dataset[i]\n",
    "        img = img.to(device).reshape(1, 3, 608, 608)\n",
    "        pred = predict_larger_image(img, model)\n",
    "        # threshold\n",
    "        pred[pred <= 0.5] = 0\n",
    "        pred[pred > 0.5] = 1\n",
    "        i = i + 1 # This is due to the way the images are labelled from 1 to 50, instead of the standard 0 to 49\n",
    "        image_filename = temp_dirname + 'prediction_' + '%.3d' % i + '.png'\n",
    "        Image.fromarray((pred * 255).astype(np.uint8)).save(image_filename)\n",
    "        image_filenames.append(image_filename)\n",
    "\n",
    "    masks_to_submission(submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net_params(net, name):\n",
    "    path = \"experiments/best_arch/\" + name + \".pth\"\n",
    "    params = torch.load(path)\n",
    "    net.load_state_dict(params)\n",
    "    net.eval()\n",
    "    net.to(\"cuda\")\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = Unet(activation_output=True) # This time we don't combine it with the loss, so we want to have the last activation\n",
    "net1 = load_net_params(net1, \"unet_simple\")\n",
    "create_submission(\"unet_simple.csv\", \"unet_simple_preds/\", net1)\n",
    "del net1 # avoid filling the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Unet(activation_output=True) # This time we don't combine it with the loss, so we want to have the last activation\n",
    "net2 = load_net_params(net2, \"unet_massach\")\n",
    "create_submission(\"unet_massach.csv\", \"unet_massach_preds/\", net2)\n",
    "del net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3 = DenseUnet(down_config=(4, 8, 16, 32), bottom=64, up_channels=(256, 128, 64, 32), activation_output=True, attention=\"grid\")\n",
    "net3 = load_net_params(net3, \"dense_unet_simple\")\n",
    "create_submission(\"dense_unet_simple.csv\", \"denseunet_simple_preds/\", net3)\n",
    "del net3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net4 = DenseUnet(down_config=(4, 8, 16, 32), bottom=64, up_channels=(256, 128, 64, 32), activation_output=True, attention=\"grid\")\n",
    "net4 = load_net_params(net4, \"dense_unet_massach\")\n",
    "create_submission(\"dense_unet_massach.csv\", \"denseunet_massach_preds/\", net4)\n",
    "del net4"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "test_architectures.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
